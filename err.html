<!doctype html>
<html lang=en>
  <head>
    <title>RuntimeError: Expected tensor for argument #1 &#39;indices&#39; to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)
 // Werkzeug Debugger</title>
    <link rel="stylesheet" href="?__debugger__=yes&amp;cmd=resource&amp;f=style.css">
    <link rel="shortcut icon"
        href="?__debugger__=yes&amp;cmd=resource&amp;f=console.png">
    <script src="?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js"></script>
    <script>
      var CONSOLE_MODE = false,
          EVALEX = true,
          EVALEX_TRUSTED = false,
          SECRET = "7xnA4LU4v1kczo4z1Rrv";
    </script>
  </head>
  <body style="background-color: #fff">
    <div class="debugger">
<h1>RuntimeError</h1>
<div class="detail">
  <p class="errormsg">RuntimeError: Expected tensor for argument #1 &#39;indices&#39; to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)
</p>
</div>
<h2 class="traceback">Traceback <em>(most recent call last)</em></h2>
<div class="traceback">
  <h3></h3>
  <ul><li><div class="frame" id="frame-1843386537520">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">1536</em>,
      in <code class="function">__call__</code></h4>
  <div class="source "><pre class="line before"><span class="ws">    </span>) -&gt; cabc.Iterable[bytes]:</pre>
<pre class="line before"><span class="ws">        </span>&#34;&#34;&#34;The WSGI server calls the Flask application object as the</pre>
<pre class="line before"><span class="ws">        </span>WSGI application. This calls :meth:`wsgi_app`, which can be</pre>
<pre class="line before"><span class="ws">        </span>wrapped to apply middleware.</pre>
<pre class="line before"><span class="ws">        </span>&#34;&#34;&#34;</pre>
<pre class="line current"><span class="ws">        </span>return self.wsgi_app(environ, start_response)
<span class="ws">        </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre></div>
</div>

<li><div class="frame" id="frame-1843386538384">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">1514</em>,
      in <code class="function">wsgi_app</code></h4>
  <div class="source "><pre class="line before"><span class="ws">            </span>try:</pre>
<pre class="line before"><span class="ws">                </span>ctx.push()</pre>
<pre class="line before"><span class="ws">                </span>response = self.full_dispatch_request()</pre>
<pre class="line before"><span class="ws">            </span>except Exception as e:</pre>
<pre class="line before"><span class="ws">                </span>error = e</pre>
<pre class="line current"><span class="ws">                </span>response = self.handle_exception(e)
<span class="ws">                </span>           ^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">            </span>except:  # noqa: B001</pre>
<pre class="line after"><span class="ws">                </span>error = sys.exc_info()[1]</pre>
<pre class="line after"><span class="ws">                </span>raise</pre>
<pre class="line after"><span class="ws">            </span>return response(environ, start_response)</pre>
<pre class="line after"><span class="ws">        </span>finally:</pre></div>
</div>

<li><div class="frame" id="frame-1843386538528">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">1511</em>,
      in <code class="function">wsgi_app</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span>ctx = self.request_context(environ)</pre>
<pre class="line before"><span class="ws">        </span>error: BaseException | None = None</pre>
<pre class="line before"><span class="ws">        </span>try:</pre>
<pre class="line before"><span class="ws">            </span>try:</pre>
<pre class="line before"><span class="ws">                </span>ctx.push()</pre>
<pre class="line current"><span class="ws">                </span>response = self.full_dispatch_request()
<span class="ws">                </span>           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">            </span>except Exception as e:</pre>
<pre class="line after"><span class="ws">                </span>error = e</pre>
<pre class="line after"><span class="ws">                </span>response = self.handle_exception(e)</pre>
<pre class="line after"><span class="ws">            </span>except:  # noqa: B001</pre>
<pre class="line after"><span class="ws">                </span>error = sys.exc_info()[1]</pre></div>
</div>

<li><div class="frame" id="frame-1843386538672">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">919</em>,
      in <code class="function">full_dispatch_request</code></h4>
  <div class="source "><pre class="line before"><span class="ws">            </span>request_started.send(self, _async_wrapper=self.ensure_sync)</pre>
<pre class="line before"><span class="ws">            </span>rv = self.preprocess_request()</pre>
<pre class="line before"><span class="ws">            </span>if rv is None:</pre>
<pre class="line before"><span class="ws">                </span>rv = self.dispatch_request()</pre>
<pre class="line before"><span class="ws">        </span>except Exception as e:</pre>
<pre class="line current"><span class="ws">            </span>rv = self.handle_user_exception(e)
<span class="ws">            </span>     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">        </span>return self.finalize_request(rv)</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span>def finalize_request(</pre>
<pre class="line after"><span class="ws">        </span>self,</pre>
<pre class="line after"><span class="ws">        </span>rv: ft.ResponseReturnValue | HTTPException,</pre></div>
</div>

<li><div class="frame" id="frame-1843386538816">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">917</em>,
      in <code class="function">full_dispatch_request</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">        </span>try:</pre>
<pre class="line before"><span class="ws">            </span>request_started.send(self, _async_wrapper=self.ensure_sync)</pre>
<pre class="line before"><span class="ws">            </span>rv = self.preprocess_request()</pre>
<pre class="line before"><span class="ws">            </span>if rv is None:</pre>
<pre class="line current"><span class="ws">                </span>rv = self.dispatch_request()
<span class="ws">                </span>     ^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">        </span>except Exception as e:</pre>
<pre class="line after"><span class="ws">            </span>rv = self.handle_user_exception(e)</pre>
<pre class="line after"><span class="ws">        </span>return self.finalize_request(rv)</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span>def finalize_request(</pre></div>
</div>

<li><div class="frame" id="frame-1843386538960">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py"</cite>,
      line <em class="line">902</em>,
      in <code class="function">dispatch_request</code></h4>
  <div class="source "><pre class="line before"><span class="ws">            </span>and req.method == &#34;OPTIONS&#34;</pre>
<pre class="line before"><span class="ws">        </span>):</pre>
<pre class="line before"><span class="ws">            </span>return self.make_default_options_response()</pre>
<pre class="line before"><span class="ws">        </span># otherwise dispatch to the handler for that endpoint</pre>
<pre class="line before"><span class="ws">        </span>view_args: dict[str, t.Any] = req.view_args  # type: ignore[assignment]</pre>
<pre class="line current"><span class="ws">        </span>return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
<span class="ws">        </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span>def full_dispatch_request(self) -&gt; Response:</pre>
<pre class="line after"><span class="ws">        </span>&#34;&#34;&#34;Dispatches the request and on top of that performs request</pre>
<pre class="line after"><span class="ws">        </span>pre and postprocessing as well as HTTP exception catching and</pre>
<pre class="line after"><span class="ws">        </span>error handling.</pre></div>
</div>

<li><div class="frame" id="frame-1843386539104">
  <h4>File <cite class="filename">"D:\Semester-8\Projek Khoir\app.py"</cite>,
      line <em class="line">26</em>,
      in <code class="function">home</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span>if not URL_REGEX.match(url):</pre>
<pre class="line before"><span class="ws">            </span>return jsonify({&#34;error&#34;:&#34;url tidak valid&#34;}), 400</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">        </span># return jsonify(dataJson)</pre>
<pre class="line before"><span class="ws">        </span>try:</pre>
<pre class="line current"><span class="ws">            </span>data = getRedditData(redditUrl=url)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">            </span>return jsonify(data)</pre>
<pre class="line after"><span class="ws">        </span>except ValueError as e:</pre>
<pre class="line after"><span class="ws">            </span>return jsonify({&#34;error&#34;: str(e)}), 400</pre>
<pre class="line after"><span class="ws">        </span>except TypeError as e:</pre>
<pre class="line after"><span class="ws">            </span>return jsonify({</pre></div>
</div>

<li><div class="frame" id="frame-1843386539248">
  <h4>File <cite class="filename">"D:\Semester-8\Projek Khoir\core\logic.py"</cite>,
      line <em class="line">51</em>,
      in <code class="function">getRedditData</code></h4>
  <div class="source "><pre class="line before"><span class="ws">                </span>&#39;created_at&#39; : (datetime.datetime.fromtimestamp(comment.created_utc)).strftime(&#39;%Y-%m-%d %H:%M:%S&#39;),</pre>
<pre class="line before"><span class="ws">            </span>})</pre>
<pre class="line before"><span class="ws">        </span>komentar_list = [comment for comment in komentar_list if comment[&#39;body&#39;].strip() != &#39;&#39;]</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">        </span>bodyComments = [preprocess_text(comment[&#39;body&#39;]) for comment in komentar_list]</pre>
<pre class="line current"><span class="ws">        </span>labelComments = [handleClassification(comment) for comment in bodyComments]
<span class="ws">        </span>                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>komentar_list = [{**c, &#39;label&#39;: l} for c, l in zip(komentar_list, labelComments)]</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span># df = pd.DataFrame(labelComments)</pre>
<pre class="line after"><span class="ws">        </span># df.to_excel(&#39;web_komentar2.xlsx&#39;, index=False)</pre></div>
</div>

<li><div class="frame" id="frame-1843386539392">
  <h4>File <cite class="filename">"D:\Semester-8\Projek Khoir\core\svm.py"</cite>,
      line <em class="line">10</em>,
      in <code class="function">handleClassification</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span>tokenizer = AutoTokenizer.from_pretrained(model_name)</pre>
<pre class="line before"><span class="ws"></span>model = AutoModelForSequenceClassification.from_pretrained(model_name)</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws"></span>def handleClassification(text):</pre>
<pre class="line before"><span class="ws">    </span>inputs = tokenizer(text, return_tensors=&#34;pt&#34;, truncation=True, padding=True, max_length=512)</pre>
<pre class="line current"><span class="ws">    </span>outputs = model(**inputs)
<span class="ws">    </span>          ^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">    </span>probs = torch.nn.functional.softmax(outputs.logits, dim=1)</pre>
<pre class="line after"><span class="ws">    </span>pred = torch.argmax(probs, dim=1).item()</pre>
<pre class="line after"><span class="ws">    </span>return 0 if pred == 0 else 1</pre></div>
</div>

<li><div class="frame" id="frame-1843386539536">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1751</em>,
      in <code class="function">_wrapped_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">    </span>def _wrapped_call_impl(self, *args, **kwargs):</pre>
<pre class="line before"><span class="ws">        </span>if self._compiled_call_impl is not None:</pre>
<pre class="line before"><span class="ws">            </span>return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]</pre>
<pre class="line before"><span class="ws">        </span>else:</pre>
<pre class="line current"><span class="ws">            </span>return self._call_impl(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span># torchrec tests the code consistency with the following code</pre>
<pre class="line after"><span class="ws">    </span># fmt: off</pre>
<pre class="line after"><span class="ws">    </span>def _call_impl(self, *args, **kwargs):</pre>
<pre class="line after"><span class="ws">        </span>forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)</pre></div>
</div>

<li><div class="frame" id="frame-1843389931600">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1762</em>,
      in <code class="function">_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span># If we don&#39;t have any hooks, we want to skip the rest of the logic in</pre>
<pre class="line before"><span class="ws">        </span># this function, and just call forward.</pre>
<pre class="line before"><span class="ws">        </span>if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_backward_pre_hooks or _global_backward_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_forward_hooks or _global_forward_pre_hooks):</pre>
<pre class="line current"><span class="ws">            </span>return forward_call(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>result = None</pre>
<pre class="line after"><span class="ws">        </span>called_always_called_hooks = set()</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>def inner():</pre></div>
</div>

<li><div class="frame" id="frame-1843389931744">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py"</cite>,
      line <em class="line">1202</em>,
      in <code class="function">forward</code></h4>
  <div class="source "><pre class="line before"><span class="ws">            </span>config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If</pre>
<pre class="line before"><span class="ws">            </span>`config.num_labels &gt; 1` a classification loss is computed (Cross-Entropy).</pre>
<pre class="line before"><span class="ws">        </span>&#34;&#34;&#34;</pre>
<pre class="line before"><span class="ws">        </span>return_dict = return_dict if return_dict is not None else self.config.use_return_dict</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line current"><span class="ws">        </span>outputs = self.roberta(
<span class="ws">        </span>          </pre>
<pre class="line after"><span class="ws">            </span>input_ids,</pre>
<pre class="line after"><span class="ws">            </span>attention_mask=attention_mask,</pre>
<pre class="line after"><span class="ws">            </span>token_type_ids=token_type_ids,</pre>
<pre class="line after"><span class="ws">            </span>position_ids=position_ids,</pre>
<pre class="line after"><span class="ws">            </span>head_mask=head_mask,</pre></div>
</div>

<li><div class="frame" id="frame-1843390075312">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1751</em>,
      in <code class="function">_wrapped_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">    </span>def _wrapped_call_impl(self, *args, **kwargs):</pre>
<pre class="line before"><span class="ws">        </span>if self._compiled_call_impl is not None:</pre>
<pre class="line before"><span class="ws">            </span>return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]</pre>
<pre class="line before"><span class="ws">        </span>else:</pre>
<pre class="line current"><span class="ws">            </span>return self._call_impl(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span># torchrec tests the code consistency with the following code</pre>
<pre class="line after"><span class="ws">    </span># fmt: off</pre>
<pre class="line after"><span class="ws">    </span>def _call_impl(self, *args, **kwargs):</pre>
<pre class="line after"><span class="ws">        </span>forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)</pre></div>
</div>

<li><div class="frame" id="frame-1843390075456">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1762</em>,
      in <code class="function">_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span># If we don&#39;t have any hooks, we want to skip the rest of the logic in</pre>
<pre class="line before"><span class="ws">        </span># this function, and just call forward.</pre>
<pre class="line before"><span class="ws">        </span>if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_backward_pre_hooks or _global_backward_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_forward_hooks or _global_forward_pre_hooks):</pre>
<pre class="line current"><span class="ws">            </span>return forward_call(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>result = None</pre>
<pre class="line after"><span class="ws">        </span>called_always_called_hooks = set()</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>def inner():</pre></div>
</div>

<li><div class="frame" id="frame-1843390075600">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py"</cite>,
      line <em class="line">805</em>,
      in <code class="function">forward</code></h4>
  <div class="source "><pre class="line before"><span class="ws">                </span>buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)</pre>
<pre class="line before"><span class="ws">                </span>token_type_ids = buffered_token_type_ids_expanded</pre>
<pre class="line before"><span class="ws">            </span>else:</pre>
<pre class="line before"><span class="ws">                </span>token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line current"><span class="ws">        </span>embedding_output = self.embeddings(
<span class="ws">        </span>                   </pre>
<pre class="line after"><span class="ws">            </span>input_ids=input_ids,</pre>
<pre class="line after"><span class="ws">            </span>position_ids=position_ids,</pre>
<pre class="line after"><span class="ws">            </span>token_type_ids=token_type_ids,</pre>
<pre class="line after"><span class="ws">            </span>inputs_embeds=inputs_embeds,</pre>
<pre class="line after"><span class="ws">            </span>past_key_values_length=past_key_values_length,</pre></div>
</div>

<li><div class="frame" id="frame-1843390075744">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1751</em>,
      in <code class="function">_wrapped_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">    </span>def _wrapped_call_impl(self, *args, **kwargs):</pre>
<pre class="line before"><span class="ws">        </span>if self._compiled_call_impl is not None:</pre>
<pre class="line before"><span class="ws">            </span>return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]</pre>
<pre class="line before"><span class="ws">        </span>else:</pre>
<pre class="line current"><span class="ws">            </span>return self._call_impl(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span># torchrec tests the code consistency with the following code</pre>
<pre class="line after"><span class="ws">    </span># fmt: off</pre>
<pre class="line after"><span class="ws">    </span>def _call_impl(self, *args, **kwargs):</pre>
<pre class="line after"><span class="ws">        </span>forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)</pre></div>
</div>

<li><div class="frame" id="frame-1843390075888">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1762</em>,
      in <code class="function">_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span># If we don&#39;t have any hooks, we want to skip the rest of the logic in</pre>
<pre class="line before"><span class="ws">        </span># this function, and just call forward.</pre>
<pre class="line before"><span class="ws">        </span>if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_backward_pre_hooks or _global_backward_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_forward_hooks or _global_forward_pre_hooks):</pre>
<pre class="line current"><span class="ws">            </span>return forward_call(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>result = None</pre>
<pre class="line after"><span class="ws">        </span>called_always_called_hooks = set()</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>def inner():</pre></div>
</div>

<li><div class="frame" id="frame-1843390076032">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py"</cite>,
      line <em class="line">109</em>,
      in <code class="function">forward</code></h4>
  <div class="source "><pre class="line before"><span class="ws">                </span>token_type_ids = buffered_token_type_ids_expanded</pre>
<pre class="line before"><span class="ws">            </span>else:</pre>
<pre class="line before"><span class="ws">                </span>token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">        </span>if inputs_embeds is None:</pre>
<pre class="line current"><span class="ws">            </span>inputs_embeds = self.word_embeddings(input_ids)
<span class="ws">            </span>                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws">        </span>token_type_embeddings = self.token_type_embeddings(token_type_ids)</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>embeddings = inputs_embeds + token_type_embeddings</pre>
<pre class="line after"><span class="ws">        </span>if self.position_embedding_type == &#34;absolute&#34;:</pre>
<pre class="line after"><span class="ws">            </span>position_embeddings = self.position_embeddings(position_ids)</pre></div>
</div>

<li><div class="frame" id="frame-1843390076176">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1751</em>,
      in <code class="function">_wrapped_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">    </span>def _wrapped_call_impl(self, *args, **kwargs):</pre>
<pre class="line before"><span class="ws">        </span>if self._compiled_call_impl is not None:</pre>
<pre class="line before"><span class="ws">            </span>return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]</pre>
<pre class="line before"><span class="ws">        </span>else:</pre>
<pre class="line current"><span class="ws">            </span>return self._call_impl(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">    </span># torchrec tests the code consistency with the following code</pre>
<pre class="line after"><span class="ws">    </span># fmt: off</pre>
<pre class="line after"><span class="ws">    </span>def _call_impl(self, *args, **kwargs):</pre>
<pre class="line after"><span class="ws">        </span>forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)</pre></div>
</div>

<li><div class="frame" id="frame-1843390076320">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py"</cite>,
      line <em class="line">1762</em>,
      in <code class="function">_call_impl</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span># If we don&#39;t have any hooks, we want to skip the rest of the logic in</pre>
<pre class="line before"><span class="ws">        </span># this function, and just call forward.</pre>
<pre class="line before"><span class="ws">        </span>if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_backward_pre_hooks or _global_backward_hooks</pre>
<pre class="line before"><span class="ws">                </span>or _global_forward_hooks or _global_forward_pre_hooks):</pre>
<pre class="line current"><span class="ws">            </span>return forward_call(*args, **kwargs)
<span class="ws">            </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>result = None</pre>
<pre class="line after"><span class="ws">        </span>called_always_called_hooks = set()</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws">        </span>def inner():</pre></div>
</div>

<li><div class="frame" id="frame-1843390076464">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\sparse.py"</cite>,
      line <em class="line">190</em>,
      in <code class="function">forward</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span>if self.padding_idx is not None:</pre>
<pre class="line before"><span class="ws">            </span>with torch.no_grad():</pre>
<pre class="line before"><span class="ws">                </span>self.weight[self.padding_idx].fill_(0)</pre>
<pre class="line before"><span class="ws"></span> </pre>
<pre class="line before"><span class="ws">    </span>def forward(self, input: Tensor) -&gt; Tensor:</pre>
<pre class="line current"><span class="ws">        </span>return F.embedding(
<span class="ws">        </span>       </pre>
<pre class="line after"><span class="ws">            </span>input,</pre>
<pre class="line after"><span class="ws">            </span>self.weight,</pre>
<pre class="line after"><span class="ws">            </span>self.padding_idx,</pre>
<pre class="line after"><span class="ws">            </span>self.max_norm,</pre>
<pre class="line after"><span class="ws">            </span>self.norm_type,</pre></div>
</div>

<li><div class="frame" id="frame-1843390081216">
  <h4>File <cite class="filename">"C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\functional.py"</cite>,
      line <em class="line">2551</em>,
      in <code class="function">embedding</code></h4>
  <div class="source "><pre class="line before"><span class="ws">        </span># XXX: equivalent to</pre>
<pre class="line before"><span class="ws">        </span># with torch.no_grad():</pre>
<pre class="line before"><span class="ws">        </span>#   torch.embedding_renorm_</pre>
<pre class="line before"><span class="ws">        </span># remove once script supports set_grad_enabled</pre>
<pre class="line before"><span class="ws">        </span>_no_grad_embedding_renorm_(weight, input, max_norm, norm_type)</pre>
<pre class="line current"><span class="ws">    </span>return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
<span class="ws">    </span>       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws"></span> </pre>
<pre class="line after"><span class="ws"></span>def embedding_bag(</pre>
<pre class="line after"><span class="ws">    </span>input: Tensor,</pre>
<pre class="line after"><span class="ws">    </span>weight: Tensor,</pre></div>
</div>
</ul>
  <blockquote>RuntimeError: Expected tensor for argument #1 &#39;indices&#39; to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)
</blockquote>
</div>

<div class="plain">
    <p>
      This is the Copy/Paste friendly version of the traceback.
    </p>
    <textarea cols="50" rows="10" name="code" readonly>Traceback (most recent call last):
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 1536, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 1514, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py&#34;, line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;D:\Semester-8\Projek Khoir\app.py&#34;, line 26, in home
    data = getRedditData(redditUrl=url)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;D:\Semester-8\Projek Khoir\core\logic.py&#34;, line 51, in getRedditData
    labelComments = [handleClassification(comment) for comment in bodyComments]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;D:\Semester-8\Projek Khoir\core\svm.py&#34;, line 10, in handleClassification
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py&#34;, line 1202, in forward
    outputs = self.roberta(
              ^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py&#34;, line 805, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py&#34;, line 109, in forward
    inputs_embeds = self.word_embeddings(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py&#34;, line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\sparse.py&#34;, line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File &#34;C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\functional.py&#34;, line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected tensor for argument #1 &#39;indices&#39; to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)
</textarea>
</div>
<div class="explanation">
  The debugger caught an exception in your WSGI application.  You can now
  look at the traceback which led to the error.  <span class="nojavascript">
  If you enable JavaScript you can also use additional features such as code
  execution (if the evalex feature is enabled), automatic pasting of the
  exceptions and much more.</span>
</div>
      <div class="footer">
        Brought to you by <strong class="arthur">DON'T PANIC</strong>, your
        friendly Werkzeug powered traceback interpreter.
      </div>
    </div>

    <div class="pin-prompt">
      <div class="inner">
        <h3>Console Locked</h3>
        <p>
          The console is locked and needs to be unlocked by entering the PIN.
          You can find the PIN printed out on the standard output of your
          shell that runs the server.
        <form>
          <p>PIN:
            <input type=text name=pin size=14>
            <input type=submit name=btn value="Confirm Pin">
        </form>
      </div>
    </div>
  </body>
</html>

<!--

Traceback (most recent call last):
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 1536, in __call__
    return self.wsgi_app(environ, start_response)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 1514, in wsgi_app
    response = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Semester-8\Projek Khoir\app.py", line 26, in home
    data = getRedditData(redditUrl=url)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Semester-8\Projek Khoir\core\logic.py", line 51, in getRedditData
    labelComments = [handleClassification(comment) for comment in bodyComments]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Semester-8\Projek Khoir\core\svm.py", line 10, in handleClassification
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py", line 1202, in forward
    outputs = self.roberta(
              ^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py", line 805, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\models\roberta\modeling_roberta.py", line 109, in forward
    inputs_embeds = self.word_embeddings(input_ids)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\modules\sparse.py", line 190, in forward
    return F.embedding(
           ^^^^^^^^^^^^
  File "C:\Users\ggm58\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torch\nn\functional.py", line 2551, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)


-->
